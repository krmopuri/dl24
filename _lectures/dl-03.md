---
type: lecture
date: 2024-01-08
title: (dl-03) Representational Power of an MLP

# optional
# please use /static_files/notes directory to store notes
# thumbnail: /static_files/path/to/image.jpg

# optional
tldr: "Multi Layered Network of Neurons can represent any artbirary function!"
  
# optional
# set it to true if you dont want this lecture to appear in the updates section
hide_from_announcments: false

# optional
links: 
    #- url: /static_files/presentations/lec.zip
    #  name: notes
    #- url: https://colab.research.google.com/drive/1TNavc9-jzJXc1N05l06KYfgaSmu7zqxN?usp=sharing
    #  name: codes
    - url: /static_files/presentations/dl-03.pdf
      name: slides
    #- url: /static_files/presentations/lec.zip
    #  name: other
---

**Suggested Readings:**

- [Chapter 4 of Michael Nielson's NNDL book](http://neuralnetworksanddeeplearning.com/chap4.html)
- [Deep Mind Blog on Universal Approximation Theorem](https://www.deep-mind.org/2023/03/26/the-universal-approximation-theorem/#Universal_Approximation_Theorem)
- [Approximation by Superposition of Sigmoid Functions](https://web.njit.edu/~usman/courses/cs675_fall18/10.1.1.441.7873.pdf)
- [Approximation Capabilities of Muitilayer
Feedforward Networks](https://web.njit.edu/~usman/courses/cs677_spring21/hornik-nn-1991.pdf)

